# RPC和线程

## 1. 线程

### 1.1 线程简介：

* 线程是一个很有用但是却可能会很难用的结构化工具。在go语言中它被称作是goroutine，在其它语言中则被称作线程。
* 程序可以用多个线程在同一时间做很多事情，每个线程被连续执行。线程存活在进程内，同时共享进程的整个用户栈。
* 每个进程拥有自己的状态，包括程序计数器，寄存器和栈。

### 1.2 使用线程的理由：

* 它可以实现在分布式系统中所需要的并发性：
    * I/O并发：
        * 一个客户端同时向多个服务器发送请求并等待服务器的回复。
        * 一个服务器同时处理多个客户端的请求。
        * 当某个客户端请求被阻塞（比如等待数据读取）时，服务器可以处理另外一个客户端的请求。
    * 多核的性能：
        * 可以在不同的CPU的核上并行地执行代码。
* 它可以带来某些便利：
    * 比如主机定期检查它的从属机是否在线的任务可以被一个新线程在后台执行，而主进程不用特别关心它的执行情况。

### 1.3 线程的替代方案：

* 可以显式地在代码中处理各种事件交互，然后将代码运行在单线程中，这样的代码被称为事件驱动程序。
* 为每个事件（比如客户端的每一个请求）维护一个状态表。
* 事件驱动程序会检查输入中是否有新的事件，然后执行每个事件的下一步操作，最后更新状态表。
* 事件驱动程序可以带给我们I/O并发，同时消除多线程带来的开销。但是它不能利用多核CPU增加性能，同时编写这样的事件驱动程序会很痛苦。

### 1.4 使用线程的挑战：

* 数据共享：
    * 因为进程内的多个线程会共享数据，很容易在读写共享数据时造成进程竞争。
        * 可以显式地在操作共享数据之前加锁。
        * 或者避免共享可以被更改的数据。
* 进程之间的互相协作：
    * 比如一个线程在产生数据，另外一个线程在消耗这些产生的数据。我们需要考虑当没有数据时如何让消费者线程等待和释放CPU，以及考虑当数据准备好之后生产者线程如何唤醒消费者线程。
        * 在go中可以使用channel, sync.Cond 或者 sync.WaitGroup来实现进程间的协作。
* 死锁：
    * 在循环获取锁或者RPC的循环通信中很容易造成死锁。

### 1.5 用多线程实现网络爬虫：

#### 1.5.1 单线程的爬虫：

```go
// Serial crawler.
func Serial(url string, fetcher Fetcher, fetched map[string]bool) {
	if fetched[url] {
		return
	}
	fetched[url] = true
	urls, err := fetcher.Fetch(url)
	if err != nil {
		return
	}
	for _, u := range urls {
		Serial(u, fetcher, fetched)
	}
	return
}
```

* 每次只能爬一个url。

#### 1.5.2 使用互斥锁的并发爬虫：

```go
type fetchState struct {
	mu      sync.Mutex
	fetched map[string]bool
}

// Concurrent crawler with shared state and Mutex.
func ConcurrentMutex(url string, fetcher Fetcher, f *fetchState) {
	f.mu.Lock()
	already := f.fetched[url]
	f.fetched[url] = true
	f.mu.Unlock()

	if already {
		return
	}

	urls, err := fetcher.Fetch(url)
	if err != nil {
		return
	}
	var done sync.WaitGroup
	for _, u := range urls {
		done.Add(1)
        u2 := u
		go func(u string) {
			defer done.Done()
			ConcurrentMutex(u, fetcher, f)
		}(u)
	}
	done.Wait()
	return
}
```

* 对于每个url创建一个新的线程进行抓取，提高了抓取效率。
* fetched被所有线程共享，所以需要在对它读写之前获取互斥锁，以免造成线程竞争。
* 可以在运行go程序时指定-race选项来检查程序在运行过程中是否有线程竞争发生。
* sync.WaitGroup可以帮我们决定是否所有的新的url已经被爬完：
    * 在开启新线程之前调用Add方法将当前计数器+1。
    * 当新线程成功执行完毕，调用Done方法将当前计数器-1。
    * Wait方法将主线程挂起直到计数器的值为0，也即是等待所有的子线程执行完毕。

#### 1.5.3 使用channel的并发爬虫：

```go
func makeState() *fetchState {
	f := &fetchState{}
	f.fetched = make(map[string]bool)
	return f
}

func worker(url string, ch chan []string, fetcher Fetcher) {
	urls, err := fetcher.Fetch(url)
	if err != nil {
		ch <- []string{}
	} else {
		ch <- urls
	}
}

func master(ch chan []string, fetcher Fetcher) {
	n := 1
	fetched := make(map[string]bool)
	for urls := range ch {
		for _, u := range urls {
			if fetched[u] == false {
				fetched[u] = true
				n += 1
				go worker(u, ch, fetcher)
			}
		}
		n -= 1
		if n == 0 {
			break
		}
	}
}

// Concurrent crawler with channels.
func ConcurrentChannel(url string, fetcher Fetcher) {
	ch := make(chan []string)
	go func() {
		ch <- []string{url}
	}()
	master(ch, fetcher)
}

```

* 因为fetched只在master线程里面使用，不会被其它worker子线程共享，所以不需要在它的操作上加上互斥锁。
* 因为每一个worker只会向channel里面发送一个数据，所以我们的计数器归0之后，我们可以认为所有的新url已经被爬完，我们可以从channel的for循环中跳出。因为我们的worker在发送数据之后不会显式的关闭channel，如果我们不跳出，for循环会永远等待channel里面的下一个新数据的到来。
* 因为channel被实现为必须要等待发送者线程和接受者线程同时空闲的时候才会进行数据的发送和接受，所以当不同的worker线程往channel里面发送数据时，不会造成线程竞争。

## 2. RPC：

### 2.1 RPC简介：

* RPC=Remote Procedure Call，即远程过程调用。它是分布式系统得以实现的关键机制之一。
* 我们的目标是创建一个易于编程的客户端/服务器通信。我们想要隐藏低层的网络协议的实现，同时将不同的数据类型转换成可以传送的格式。

### 2.2 RPC示例：

```go
//
// Client
//

func connect() *rpc.Client {
	client, err := rpc.Dial("tcp", ":1234")
	if err != nil {
		log.Fatal("dialing:", err)
	}
	return client
}

func get(key string) string {
	client := connect()
	args := GetArgs{"subject"}
	reply := GetReply{}
	err := client.Call("KV.Get", &args, &reply)
	if err != nil {
		log.Fatal("error:", err)
	}
	client.Close()
	return reply.Value
}

func put(key string, val string) {
	client := connect()
	args := PutArgs{"subject", "6.824"}
	reply := PutReply{}
	err := client.Call("KV.Put", &args, &reply)
	if err != nil {
		log.Fatal("error:", err)
	}
	client.Close()
}

//
// Server
//

type KV struct {
	mu   sync.Mutex
	data map[string]string
}

func server() {
	kv := new(KV)
	kv.data = map[string]string{}
	rpcs := rpc.NewServer()
	rpcs.Register(kv)
	l, e := net.Listen("tcp", ":1234")
	if e != nil {
		log.Fatal("listen error:", e)
	}
	go func() {
		for {
			conn, err := l.Accept()
			if err == nil {
				go rpcs.ServeConn(conn)
			} else {
				break
			}
		}
		l.Close()
	}()
}

func (kv *KV) Get(args *GetArgs, reply *GetReply) error {
	kv.mu.Lock()
	defer kv.mu.Unlock()

	val, ok := kv.data[args.Key]
	if ok {
		reply.Err = OK
		reply.Value = val
	} else {
		reply.Err = ErrNoKey
		reply.Value = ""
	}
	return nil
}

func (kv *KV) Put(args *PutArgs, reply *PutReply) error {
	kv.mu.Lock()
	defer kv.mu.Unlock()

	kv.data[args.Key] = args.Value
	reply.Err = OK
	return nil
}
```

* go的rpc库在客户端连接远程服务器时是将服务器的名字和端口号作为参数来创建连接。对于大型系统而言，一般会有独立的名字或者配置服务器。
* go的rpc库在传递不同类型的数据时，可以从传入的指针所指的位置复制数据。
    * channel或者函数类型不能作为数据传输。


### 2.3 使用RPC可能会碰到的问题：

* 可能会碰到诸如丢包，断网，服务器运行缓慢，服务器崩溃的情况。
* 在客户端看来：
    * 一直没有收到远程服务器的响应。
    * 客户端并不知道远程服务器是否接收到了请求：
        * 可能服务器没有收到请求。
        * 可能服务器在发送响应之前崩溃了。
        * 可能服务器在发送响应之前网络崩溃了。

### 2.4 对RPC碰到的问题的简单应对方案：

* 客户端尝试等待响应一段时间。
* 如果一段时间过后没有响应则重新发送之前的请求。
* 重复几次上述两个步骤。
* 如果仍然没有响应，放弃本次请求并返回错误信息。
* 上述方案适用于只读的操作或者是重复运行对结果没有影响的操作（比如检查数据库的某条数据是否存在）。

### 2.5 对RPC碰到的问题的更好的应对方案：

* 服务器检查重复的客户端请求，并针对当前请求返回上次执行后的结果，而不用重复执行当前请求。
    * 客户端可以在发送每个请求的时候加入一个唯一的id给服务器端进行检查。
* 如何设定id的值：
    * 每一个客户端有一个独立的id（可能是一个随机的大整数）。
    * 每一个客户端的RPC请求都有自己的序号。
    * 每一个客户端一次只能发送一个RPC请求，这样根据新请求的序列号，服务器可以丢掉所有之前发过来的序列号小于当前新请求序列号的请求。
* 当原本的请求还在执行时，服务器如何检查重复的请求：
    * 可以在执行每个RPC请求时加入标记，确定是等待还是忽略当前的请求。
* 如果服务器崩溃或者重启了：
    * 如果重复信息是放在内存里，服务器重启之后会重新处理重复的请求。
    * 可以考虑将重复的信息持久化到硬盘上。
    * 同时还可以考虑将持久化后的重复信息复制到备份服务器上。
* GO的RPC库采用的就是上述的应对方案的简单形式：
    * go的RPC只发送请求一次，所以服务器端看不到重复的请求。
    * go的RPC调用如果没有收到响应则会返回错误。

